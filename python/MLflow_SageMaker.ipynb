{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch MLflow\n",
    "Patch MLflow with `whylogs.enable_mlflow()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whylogs\n",
    "whylogs.enable_mlflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import MLFlow\n",
    "\n",
    "Set tracking URI to local host.\n",
    "\n",
    "We already have an MLflow server running at `http://localhost:5000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(mlflow.__version__)\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model\n",
    "\n",
    "We build a simple ElasticNet model using the wine quality model.\n",
    "\n",
    "This is adopted from the MLflow example at: https://mlflow.org/docs/latest/tutorials-and-examples/tutorial.html\n",
    "\n",
    "First we need to load the data and split it into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "# Read the wine-quality csv file from the URL\n",
    "csv_url = (\n",
    "    \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    ")\n",
    "try:\n",
    "    data = pd.read_csv(csv_url, sep=\";\")\n",
    "except Exception as e:\n",
    "    logger.exception(\n",
    "        \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\n",
    "    )\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "We train the model and register them with MLflow.\n",
    "\n",
    "Since we already enable whylogs integration, whylogs will pick up the `.whylogs.yaml` in the current directory and add it as a model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# .whylogs.yaml\n",
      "\n",
      "# Example WhyLogs YAML configuration\n",
      "project: demo-project\n",
      "pipeline: sagemaker-pipeline\n",
      "verbose: false\n",
      "writers:\n",
      "# Save out the full protobuf datasketches data locally\n",
      "- formats:\n",
      "    - protobuf\n",
      "  output_path: s3://whylabs-demo-artifacts-us-west-2/sagemaker\n",
      "  path_template: $name/dataset_profile\n",
      "  filename_template: datase_profile-$dataset_timestamp\n",
      "  type: s3\n"
     ]
    }
   ],
   "source": [
    "!cat .whylogs.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 0.7931640229276851\n",
      "  MAE: 0.6271946374319586\n",
      "  R2: 0.10862644997792614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ElasticnetWineModel' already exists. Creating a new version of this model...\n",
      "2021/01/21 21:37:05 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: ElasticnetWineModel, version 8\n",
      "Created version '8' of model 'ElasticnetWineModel'.\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "l1_ratio = 0.5\n",
    "with mlflow.start_run():\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "    # Model registry does not work with file store\n",
    "    if tracking_url_type_store != \"file\":\n",
    "        # Register the model\n",
    "        # There are other ways to use the Model Registry, which depends on the use case,\n",
    "        # please refer to the doc for more information:\n",
    "        # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "        mlflow.sklearn.log_model(lr, \"model\", registered_model_name=\"ElasticnetWineModel\")\n",
    "    else:\n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine run artifact\n",
    "\n",
    "We can go to MLflow interfact to see the run artifacts or examine the run info using MLflow API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RunInfo: artifact_uri='data/0/c67968018081464eabf1bece1dde68f3/artifacts', end_time=1611293825505, experiment_id='0', lifecycle_stage='active', run_id='c67968018081464eabf1bece1dde68f3', run_uuid='c67968018081464eabf1bece1dde68f3', start_time=1611293824555, status='FINISHED', user_id='andy'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_run = mlflow.list_run_infos(experiment_id=\"0\")[0]\n",
    "latest_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model artifacts\n",
    "You should see that `.whylogs.yaml` is appended with the model artifacts.\n",
    "\n",
    "We also add `whylogs` as a dependency in `conda.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<FileInfo: file_size=378, is_dir=False, path='model/.whylogs.yaml'>,\n",
       " <FileInfo: file_size=357, is_dir=False, path='model/MLmodel'>,\n",
       " <FileInfo: file_size=178, is_dir=False, path='model/conda.yaml'>,\n",
       " <FileInfo: file_size=645, is_dir=False, path='model/model.pkl'>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "info = client.list_artifacts(run_id=latest_run.run_id, path=\"model\")\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting in SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the base container\n",
    "\n",
    "Before you start, you'll need to push the base MLflow container to your AWS account. \n",
    "See https://www.mlflow.org/docs/latest/cli.html#mlflow-sagemaker-build-and-push-container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mlflow sagemaker build-and-push-container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "\n",
    "MLflow makes it really easy to deploy the model.\n",
    "\n",
    "We have setup a Sagemaker execution role that has the S3 write permission to the `whylabs-demo-artifacts-us-west-2` bucket (set in `.whylogs.yaml`)\n",
    "\n",
    "Note that it takes a while for a model deployment to reach Stable state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/01/21 21:50:59 INFO mlflow.sagemaker: Using the python_function flavor for deployment!\n",
      "2021/01/21 21:50:59 INFO mlflow.sagemaker: No model data bucket specified, using the default bucket\n",
      "2021/01/21 21:51:01 INFO mlflow.sagemaker: Default bucket `mlflow-sagemaker-us-west-2-207285235248` already exists. Skipping creation.\n",
      "2021/01/21 21:51:01 INFO mlflow.sagemaker: tag response: {'ResponseMetadata': {'RequestId': '55E816D19DDB953D', 'HostId': 't7zVriBj3Gdtwn7nXaIMGWfsLBpZqTnzBWF+oEjdnAP7g79bEgJ9XtTwFNNAn8AgQDcFkiQGX5Y=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 't7zVriBj3Gdtwn7nXaIMGWfsLBpZqTnzBWF+oEjdnAP7g79bEgJ9XtTwFNNAn8AgQDcFkiQGX5Y=', 'x-amz-request-id': '55E816D19DDB953D', 'date': 'Fri, 22 Jan 2021 05:51:02 GMT', 'content-length': '0', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}\n",
      "2021/01/21 21:51:01 INFO mlflow.sagemaker: Creating new endpoint with name: whylogs ...\n",
      "2021/01/21 21:51:02 INFO mlflow.sagemaker: Created model with arn: arn:aws:sagemaker:us-west-2:207285235248:model/whylogs-model-lesbbs-gqzcqas6ylo-bcg\n",
      "2021/01/21 21:51:02 INFO mlflow.sagemaker: Created endpoint configuration with arn: arn:aws:sagemaker:us-west-2:207285235248:endpoint-config/whylogs-config-xn7ixhfgt46h-ucr1xpnabq\n",
      "2021/01/21 21:51:02 INFO mlflow.sagemaker: Created endpoint with arn: arn:aws:sagemaker:us-west-2:207285235248:endpoint/whylogs\n",
      "2021/01/21 21:51:02 INFO mlflow.sagemaker: Waiting for the deployment operation to complete...\n",
      "2021/01/21 21:51:02 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:51:22 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:51:43 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:52:03 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:52:23 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:52:43 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:53:04 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:53:24 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:53:44 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:54:04 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:54:25 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:54:45 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:55:05 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:55:26 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:55:46 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:56:06 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:56:26 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:56:46 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:57:07 INFO mlflow.sagemaker: Waiting for endpoint to reach the \"InService\" state. Current endpoint status: \"Creating\"\n",
      "2021/01/21 21:57:17 INFO mlflow.sagemaker: The deployment operation completed successfully with message: \"The SageMaker endpoint was created successfully.\"\n"
     ]
    }
   ],
   "source": [
    "import mlflow.sagemaker\n",
    "\n",
    "mlflow.sagemaker.deploy(\n",
    "    app_name=\"whylogs\", \n",
    "    model_uri=f\"runs:/{latest_run.run_id}/model\", \n",
    "    execution_role_arn=\"arn:aws:iam::207285235248:role/service-role/AmazonSageMaker-ExecutionRole-20200529T103706\",\n",
    "    mode=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker API Input\n",
    "\n",
    "The input of SageMaker API is based on Pandas JSON wplit `split` orient. Example is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"columns\":[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"],\"index\":[1316,1507,849],\"data\":[[5.4,0.74,0.0,1.2,0.041,16.0,46.0,0.99258,4.01,0.59,12.5],[7.5,0.38,0.57,2.3,0.106,5.0,12.0,0.99605,3.36,0.55,11.4],[6.4,0.63,0.21,1.6,0.08,12.0,32.0,0.99689,3.58,0.66,9.8]]}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head(3).to_json(orient='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the endpoint\n",
    "\n",
    "First we create a Sagemaker client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the endpoint and see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.731344540042413, 5.247960704489776, 5.754717372954283, 5.751114228483034, 5.635968698470214, 5.650958816069663, 5.6375782441532145, 5.781663284991655, 5.578837218114763, 5.603618905770178]\n"
     ]
    }
   ],
   "source": [
    "res = client.invoke_endpoint(EndpointName=\"hackathon\", ContentType=\"application/json\", Body=test_x.head(10).to_json(orient=\"split\"))\n",
    "print(res['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run our data for a while\n",
    "To demonstrate the ability to run whylogs in a live inference environment, we'll run the above request a few time.\n",
    "\n",
    "By default, whylogs writes to S3 every minutes (configurable). The short interval is for demo and testing purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(1, 30):\n",
    "    res = client.invoke_endpoint(EndpointName=\"whylogs\", ContentType=\"application/json\", Body=test_x.to_json(orient=\"split\"))\n",
    "    res['Body'].read().decode()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the data in the bucket\n",
    "\n",
    "We verify that whylogs sends data in a period manner to the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 22:16:27      38653 sagemaker/live/dataset_profile/protobuf/datase_profile-1611296040000.2021-01-22_06-14.bin\n",
      "2021-01-21 22:17:57      41127 sagemaker/live/dataset_profile/protobuf/datase_profile-1611296100000.2021-01-22_06-15.bin\n",
      "2021-01-21 22:18:29      38653 sagemaker/live/dataset_profile/protobuf/datase_profile-1611296160000.2021-01-22_06-16.bin\n",
      "2021-01-21 22:18:50      45135 sagemaker/live/dataset_profile/protobuf/datase_profile-1611296220000.2021-01-22_06-17.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive s3://whylabs-demo-artifacts-us-west-2/sagemaker/live/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to analyze this data using `whylogs` visualization. Check out our example repo for more notebooks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
